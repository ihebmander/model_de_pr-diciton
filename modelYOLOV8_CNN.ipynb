{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQLFJxvvfYmkZgMXFYNl9a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihebmander/model_de_pr-diciton/blob/main/modelYOLOV8_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python-headless matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYoquG0QHr8b",
        "outputId": "0d1b1042-3c2b-49aa-e993-ab7ef5a7a5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.122-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.122-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.122 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLKt3Te-IWQG",
        "outputId": "98b549ae-87db-4426-edfe-acf9a34d08a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Charger un modèle pré-entraîné ou le tien\n",
        "model = YOLO('yolov8n.pt')  # ou 'chemin/vers/ton_modele.pt'\n",
        "\n",
        "# Entraîner (si nécessaire)\n",
        "model.train(data='/content/dap_dataset/dap_dataset/data.yaml', epochs=50, imgsz=640)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uQd2arzIxs7",
        "outputId": "c5304bd0-b22e-4d19-8fdc-100b43c7a7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.122 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/dap_dataset/dap_dataset/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 13.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 807.8±387.4 MB/s, size: 36.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dap_dataset/dap_dataset/labels/train... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 49.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dap_dataset/dap_dataset/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 662.9±38.4 MB/s, size: 35.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dap_dataset/dap_dataset/labels/val... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 894.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dap_dataset/dap_dataset/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50         0G      2.681      3.557      3.212          5        640: 100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0623     0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50         0G      3.015      5.051       3.35          3        640: 100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0623     0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50         0G      3.308      3.336      3.305          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0829     0.0249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50         0G      2.692      3.826      2.771          5        640: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0829     0.0249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50         0G      2.152      2.949      2.179         10        640: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.124     0.0373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50         0G      3.197      3.531      3.074          7        640: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.124     0.0373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50         0G      2.258      3.183       2.28          6        640: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.495     0.0991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50         0G      2.086       3.35      2.323          6        640: 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.495     0.0826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50         0G      1.818       3.71      2.153          4        640: 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.248     0.0661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50         0G      2.154      3.525      2.325          6        640: 100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.248     0.0868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50         0G      1.492      2.817      1.761          5        640: 100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.165     0.0662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50         0G      1.638        2.8      1.861          8        640: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.165     0.0496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50         0G      1.874      3.393      2.054          6        640: 100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.124     0.0515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50         0G      1.386      2.693      1.851          5        640: 100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0829     0.0332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50         0G      1.828      2.711      2.003          9        640: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0454     0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50         0G      1.125      2.313      1.536          4        640: 100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0358     0.0179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50         0G      1.822      2.877      1.708          5        640: 100%|██████████| 1/1 [00:03<00:00,  3.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0314     0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50         0G      1.129      2.544      1.372          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0314     0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50         0G      1.511      2.341      1.569          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0358     0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50         0G      1.297      1.711      1.392          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0358     0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50         0G      1.521      2.328      1.877          7        640: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0623     0.0256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50         0G      1.195      2.389       1.44          6        640: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0623     0.0256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50         0G      1.544      2.325      1.499          9        640: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.288     0.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50         0G      1.381      1.846      1.585          6        640: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.288     0.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50         0G      1.019      1.961      1.274          7        640: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.165     0.0508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50         0G      1.567      2.439      1.689          8        640: 100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.165     0.0508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50         0G      1.516      2.132      1.807          6        640: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.275     0.0589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50         0G      1.224      1.859      1.431          8        640: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.275     0.0589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50         0G      1.029      2.642      1.399          5        640: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.199     0.0275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50         0G      1.064       1.82      1.464          5        640: 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.199     0.0275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50         0G      1.331      2.021      1.519          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.161     0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50         0G      1.075      1.906      1.296          9        640: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.161     0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50         0G     0.9009      2.095      1.242          4        640: 100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.201     0.0252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50         0G      1.145       1.67      1.238         11        640: 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.201     0.0252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50         0G     0.7332      1.512      1.258          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.186     0.0398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50         0G       1.01      1.921      1.454          5        640: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.186     0.0398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50         0G      1.322      2.648      1.621          5        640: 100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1     0.0952     0.0214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50         0G      1.181      1.862      1.356          5        640: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1     0.0952     0.0214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50         0G      1.201      1.798      1.353          8        640: 100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0829     0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50         0G     0.5587      1.389      1.104          7        640: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0829     0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50         0G     0.6392      1.532     0.9309          3        640: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0829     0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50         0G     0.6477      1.576     0.9443          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5     0.0829     0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50         0G     0.5042      1.548      1.016          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.104     0.0243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50         0G     0.6438      1.785      1.209          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.104     0.0243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50         0G       0.82      1.923       1.29          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.104     0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50         0G     0.6144      1.834      1.102          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1      0.104     0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50         0G     0.5652      1.602      1.136          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1        0.3     0.0579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50         0G     0.5598      1.606     0.8799          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1        0.3     0.0579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50         0G     0.7776      1.636     0.9785          3        640: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1        0.3     0.0566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50         0G     0.4977      1.423     0.8928          3        640: 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00333          1        0.3     0.0566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 0.050 hours.\n",
            "Optimizer stripped from runs/detect/train5/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train5/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train5/weights/best.pt...\n",
            "Ultralytics 8.3.122 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00167        0.5      0.495     0.0991\n",
            "Speed: 2.5ms preprocess, 236.6ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x786d15c14650>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,    0.001665,   0.0016617,   0.0016583,    0.001655,   0.0016517,   0.0016483,\n",
              "           0.001645,   0.0016416,   0.0016383,    0.001635,   0.0016316,   0.0016283,    0.001625,   0.0016216,   0.0016183,   0.0016149,   0.0016116,   0.0016083,   0.0016049,   0.0016016,   0.0015983,   0.0015949,   0.0015916,   0.0015883,   0.0015849,   0.0015816,   0.0015782,   0.0015749,   0.0015716,\n",
              "          0.0015682,   0.0015649,   0.0015616,   0.0015582,   0.0015549,   0.0015516,   0.0015482,   0.0015449,   0.0015415,   0.0015382,   0.0015349,   0.0015315,   0.0015282,   0.0015249,   0.0015215,   0.0015182,   0.0015148,   0.0015115,   0.0015082,   0.0015048,   0.0015015,   0.0014982,   0.0014948,\n",
              "          0.0014915,   0.0014882,   0.0014848,   0.0014815,   0.0014781,   0.0014748,   0.0014715,   0.0014681,   0.0014648,   0.0014615,   0.0014581,   0.0014548,   0.0014515,   0.0014481,   0.0014448,   0.0014414,   0.0014381,   0.0014348,   0.0014314,   0.0014281,   0.0014248,   0.0014214,   0.0014181,\n",
              "          0.0014147,   0.0014114,   0.0014081,   0.0014047,   0.0014014,   0.0013981,   0.0013947,   0.0013914,   0.0013881,   0.0013847,   0.0013814,    0.001378,   0.0013747,   0.0013714,    0.001368,   0.0013647,   0.0013614,    0.001358,   0.0013547,   0.0013514,    0.001348,   0.0013447,   0.0013413,\n",
              "           0.001338,   0.0013347,   0.0013313,    0.001328,   0.0013247,   0.0013213,    0.001318,   0.0013146,   0.0013113,    0.001308,   0.0013046,   0.0013013,    0.001298,   0.0012946,   0.0012913,    0.001288,   0.0012846,   0.0012813,   0.0012779,   0.0012746,   0.0012713,   0.0012679,   0.0012646,\n",
              "          0.0012613,   0.0012579,   0.0012546,   0.0012513,   0.0012479,   0.0012446,   0.0012412,   0.0012379,   0.0012346,   0.0012312,   0.0012279,   0.0012246,   0.0012212,   0.0012179,   0.0012145,   0.0012112,   0.0012079,   0.0012045,   0.0012012,   0.0011979,   0.0011945,   0.0011912,   0.0011879,\n",
              "          0.0011845,   0.0011812,   0.0011778,   0.0011745,   0.0011712,   0.0011678,   0.0011645,   0.0011612,   0.0011578,   0.0011545,   0.0011512,   0.0011478,   0.0011445,   0.0011411,   0.0011378,   0.0011345,   0.0011311,   0.0011278,   0.0011245,   0.0011211,   0.0011178,   0.0011144,   0.0011111,\n",
              "          0.0011078,   0.0011044,   0.0011011,   0.0010978,   0.0010944,   0.0010911,   0.0010878,   0.0010844,   0.0010811,   0.0010777,   0.0010744,   0.0010711,   0.0010677,   0.0010644,   0.0010611,   0.0010577,   0.0010544,   0.0010511,   0.0010477,   0.0010444,    0.001041,   0.0010377,   0.0010344,\n",
              "           0.001031,   0.0010277,   0.0010244,    0.001021,   0.0010177,   0.0010143,    0.001011,   0.0010077,   0.0010043,    0.001001,  0.00099766,  0.00099433,  0.00099099,  0.00098765,  0.00098432,  0.00098098,  0.00097764,  0.00097431,  0.00097097,  0.00096763,   0.0009643,  0.00096096,  0.00095762,\n",
              "         0.00095429,  0.00095095,  0.00094761,  0.00094428,  0.00094094,   0.0009376,  0.00093427,  0.00093093,  0.00092759,  0.00092426,  0.00092092,  0.00091758,  0.00091425,  0.00091091,  0.00090757,  0.00090424,   0.0009009,  0.00089756,  0.00089423,  0.00089089,  0.00088755,  0.00088422,  0.00088088,\n",
              "         0.00087754,  0.00087421,  0.00087087,  0.00086753,   0.0008642,  0.00086086,  0.00085752,  0.00085419,  0.00085085,  0.00084751,  0.00084418,  0.00084084,   0.0008375,  0.00083417,  0.00083083,  0.00082749,  0.00082416,  0.00082082,  0.00081748,  0.00081415,  0.00081081,  0.00080747,  0.00080414,\n",
              "          0.0008008,  0.00079746,  0.00079413,  0.00079079,  0.00078745,  0.00078412,  0.00078078,  0.00077744,  0.00077411,  0.00077077,  0.00076743,   0.0007641,  0.00076076,  0.00075742,  0.00075409,  0.00075075,  0.00074741,  0.00074408,  0.00074074,   0.0007374,  0.00073407,  0.00073073,  0.00072739,\n",
              "         0.00072406,  0.00072072,  0.00071738,  0.00071405,  0.00071071,  0.00070737,  0.00070404,   0.0007007,  0.00069736,  0.00069403,  0.00069069,  0.00068735,  0.00068402,  0.00068068,  0.00067734,  0.00067401,  0.00067067,  0.00066733,    0.000664,  0.00066066,  0.00065732,  0.00065399,  0.00065065,\n",
              "         0.00064731,  0.00064398,  0.00064064,   0.0006373,  0.00063397,  0.00063063,  0.00062729,  0.00062396,  0.00062062,  0.00061728,  0.00061395,  0.00061061,  0.00060727,  0.00060394,   0.0006006,  0.00059726,  0.00059393,  0.00059059,  0.00058725,  0.00058392,  0.00058058,  0.00057724,  0.00057391,\n",
              "         0.00057057,  0.00056723,   0.0005639,  0.00056056,  0.00055722,  0.00055389,  0.00055055,  0.00054721,  0.00054388,  0.00054054,   0.0005372,  0.00053387,  0.00053053,  0.00052719,  0.00052386,  0.00052052,  0.00051718,  0.00051385,  0.00051051,  0.00050717,  0.00050384,   0.0005005,  0.00049716,\n",
              "         0.00049383,  0.00049049,  0.00048715,  0.00048382,  0.00048048,  0.00047714,  0.00047381,  0.00047047,  0.00046713,   0.0004638,  0.00046046,  0.00045712,  0.00045379,  0.00045045,  0.00044711,  0.00044378,  0.00044044,   0.0004371,  0.00043377,  0.00043043,  0.00042709,  0.00042376,  0.00042042,\n",
              "         0.00041708,  0.00041375,  0.00041041,  0.00040707,  0.00040374,   0.0004004,  0.00039706,  0.00039373,  0.00039039,  0.00038705,  0.00038372,  0.00038038,  0.00037704,  0.00037371,  0.00037037,  0.00036703,   0.0003637,  0.00036036,  0.00035702,  0.00035369,  0.00035035,  0.00034701,  0.00034368,\n",
              "         0.00034034,    0.000337,  0.00033367,  0.00033033,  0.00032699,  0.00032366,  0.00032032,  0.00031698,  0.00031365,  0.00031031,  0.00030697,  0.00030364,   0.0003003,  0.00029696,  0.00029363,  0.00029029,  0.00028695,  0.00028362,  0.00028028,  0.00027694,  0.00027361,  0.00027027,  0.00026693,\n",
              "          0.0002636,  0.00026026,  0.00025692,  0.00025359,  0.00025025,  0.00024691,  0.00024358,  0.00024024,   0.0002369,  0.00023357,  0.00023023,  0.00022689,  0.00022356,  0.00022022,  0.00021688,  0.00021355,  0.00021021,  0.00020687,  0.00020354,   0.0002002,  0.00019686,  0.00019353,  0.00019019,\n",
              "         0.00018685,  0.00018352,  0.00018018,  0.00017684,  0.00017351,  0.00017017,  0.00016683,   0.0001635,  0.00016016,  0.00015682,  0.00015349,  0.00015015,  0.00014681,  0.00014348,  0.00014014,   0.0001368,  0.00013347,  0.00013013,  0.00012679,  0.00012346,  0.00012012,  0.00011678,  0.00011345,\n",
              "         0.00011011,  0.00010677,  0.00010344,   0.0001001,  9.6763e-05,  9.3427e-05,   9.009e-05,  8.6753e-05,  8.3417e-05,   8.008e-05,  7.6743e-05,  7.3407e-05,   7.007e-05,  6.6733e-05,  6.3397e-05,   6.006e-05,  5.6723e-05,  5.3387e-05,   5.005e-05,  4.6713e-05,  4.3377e-05,   4.004e-05,  3.6703e-05,\n",
              "         3.3367e-05,   3.003e-05,  2.6693e-05,  2.3357e-05,   2.002e-05,  1.6683e-05,  1.3347e-05,   1.001e-05,  6.6733e-06,  3.3367e-06,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0033223,   0.0033223,   0.0033223,   0.0033223,   0.0076656,    0.007669,   0.0076724,   0.0076758,   0.0076792,   0.0076826,    0.007686,   0.0076894,    0.008308,     0.29646,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0016667,   0.0016667,   0.0016667,   0.0016667,   0.0038624,   0.0038642,   0.0038659,   0.0038676,   0.0038693,    0.003871,   0.0038728,   0.0038745,   0.0041888,     0.21069,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[        0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,         0.5,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.13875725)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([   0.099127])\n",
              "names: {0: 'DAP'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': np.float64(0.0016666666666666668), 'metrics/recall(B)': np.float64(0.5), 'metrics/mAP50(B)': np.float64(0.495425), 'metrics/mAP50-95(B)': np.float64(0.0991275), 'fitness': np.float64(0.13875725)}\n",
              "save_dir: PosixPath('runs/detect/train5')\n",
              "speed: {'preprocess': 2.5007234999065986, 'inference': 236.58050799986086, 'loss': 0.001003500074148178, 'postprocess': 5.426018499974816}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file_path = \"/content/dap_dataset.zip\"\n",
        "extract_to_path = \"/content/dap_dataset\"\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)"
      ],
      "metadata": {
        "id": "uVhYLXQkJX1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Répertoire contenant les images\n",
        "image_folder = '/content/dap_dataset/dap_dataset/images'\n",
        "output_folder = '/content/dap_dataset'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "detected_images = []\n",
        "image_names = []\n",
        "\n",
        "for img_name in os.listdir(image_folder):\n",
        "    if img_name.endswith('.jpg') or img_name.endswith('.png'):\n",
        "        img_path = os.path.join(image_folder, img_name)\n",
        "        results = model(img_path)\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes.xyxy.cpu().numpy()\n",
        "            img = cv2.imread(img_path)\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                crop = img[y1:y2, x1:x2]\n",
        "                resized = cv2.resize(crop, (128, 128))\n",
        "                output_path = os.path.join(output_folder, img_name)\n",
        "                cv2.imwrite(output_path, resized)\n",
        "                detected_images.append(resized)\n",
        "                image_names.append(img_name)\n"
      ],
      "metadata": {
        "id": "tU3-_-uAQZzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le CSV avec les quantités réelles\n",
        "csv_path = '/content/projet/projet/labels.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Associer image détectée à sa quantité\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for img_name, img in zip(image_names, detected_images):\n",
        "    quantity = df[df['filename'] == img_name]['level'].values[0]\n",
        "    X.append(img / 255.0)\n",
        "    y.append(quantity)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "id": "H5Fj8FVNQ7f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model_cnn = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)  # sortie régression\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "model_cnn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "vMPFozXKRHU-",
        "outputId": "c198d3ab-fbd8-424b-ee24-439c6e43a36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m6,422,592\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,592</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,515,905\u001b[0m (24.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,515,905</span> (24.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,515,905\u001b[0m (24.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,515,905</span> (24.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Charger le CSV avec les noms de fichiers\n",
        "df = pd.read_csv('/content/projet/projet/labels.csv')\n",
        "X = df[['filename']]  # Assurez-vous que cette colonne existe et n'est pas vide\n",
        "image_folder = '/content/dap_dataset/dap_dataset/images/train'  # Chemin vers le dossier des images\n",
        "\n",
        "\n",
        "# On va charger et convertir toutes les images en tableaux numpy\n",
        "X_images = []\n",
        "\n",
        "for index, row in X.iterrows():\n",
        "    path = os.path.join(image_folder, row['filename'])  # Construire le chemin complet de l'image\n",
        "    img = cv2.imread(path)         # Charger l'image\n",
        "\n",
        "    # Vérifier si l'image a été chargée correctement\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (128, 128))  # Redimensionner toutes les images à la même taille\n",
        "        img = img.astype('float32') / 255.0  # Normaliser\n",
        "        X_images.append(img)\n",
        "    else:\n",
        "        print(f\"Erreur: Image non trouvée: {path}\")\n",
        "\n",
        "X = np.array(X_images)  # (nb_images, 128, 128, 3)\n"
      ],
      "metadata": {
        "id": "hYOjhmUGTG3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "history = model_cnn.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEStWioFRQaW",
        "outputId": "4850698a-f78a-4e44-d272-7b12c371686a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 5725.6211 - mae: 74.6700 - val_loss: 26.0193 - val_mae: 5.1009\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 1132.1605 - mae: 31.3690 - val_loss: 9719.4102 - val_mae: 98.5871\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 3637.4246 - mae: 58.9724 - val_loss: 3017.0786 - val_mae: 54.9279\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 431.9552 - mae: 16.7642 - val_loss: 433.5609 - val_mae: 20.8221\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 409.7239 - mae: 16.1878 - val_loss: 41.4493 - val_mae: 6.4381\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 1057.0282 - mae: 30.1680 - val_loss: 14.5805 - val_mae: 3.8184\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 1220.9714 - mae: 32.7781 - val_loss: 73.0650 - val_mae: 8.5478\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 948.4324 - mae: 28.3191 - val_loss: 346.0712 - val_mae: 18.6030\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 496.0102 - mae: 18.6880 - val_loss: 1059.6572 - val_mae: 32.5524\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 176.3339 - mae: 12.8066 - val_loss: 2275.3167 - val_mae: 47.7003\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 235.4732 - mae: 10.9348 - val_loss: 3381.8521 - val_mae: 58.1537\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 523.6440 - mae: 19.2885 - val_loss: 3554.0288 - val_mae: 59.6157\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - loss: 580.8650 - mae: 20.7319 - val_loss: 2806.4143 - val_mae: 52.9756\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657ms/step - loss: 356.5528 - mae: 14.4083 - val_loss: 1831.7325 - val_mae: 42.7987\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step - loss: 168.3819 - mae: 9.5322 - val_loss: 1096.0923 - val_mae: 33.1073\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 165.1356 - mae: 12.3916 - val_loss: 681.0255 - val_mae: 26.0965\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 269.6312 - mae: 14.4758 - val_loss: 505.6566 - val_mae: 22.4868\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906ms/step - loss: 357.9052 - mae: 15.5310 - val_loss: 493.4373 - val_mae: 22.2134\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - loss: 364.4544 - mae: 15.5767 - val_loss: 620.3578 - val_mae: 24.9070\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - loss: 293.0784 - mae: 14.7222 - val_loss: 899.9456 - val_mae: 29.9991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti5G2SXxR7TM",
        "outputId": "624fd676-abe1-4055-a964-7b509b61f609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (4, 128, 128, 3)\n",
            "y shape: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Courbe perte\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Courbe de perte\")\n",
        "plt.show()\n",
        "\n",
        "# Prédictions\n",
        "y_pred = model_cnn.predict(X_test)\n",
        "\n",
        "for true, pred in zip(y_test[:10], y_pred[:10]):\n",
        "    print(f\"Vrai : {true:.2f} - Prédit : {pred[0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ggT2C3OlUyMk",
        "outputId": "fb99a94c-6f91-48f2-a213-44785fc4bbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "Vrai : 40.00 - Prédit : 70.00\n"
          ]
        }
      ]
    }
  ]
}